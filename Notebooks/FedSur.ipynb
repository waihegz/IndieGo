{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import jax \n",
    "import jax.numpy as jnp\n",
    "from jax import random, scipy\n",
    "from typing import NamedTuple\n",
    "from tqdm import tqdm\n",
    "import matplotlib.pyplot as plt\n",
    "import wandb\n",
    "guassian_pdf = jax.scipy.stats.multivariate_normal.pdf "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def get_psd(sigma):\n",
    "    M, v = jnp.linalg.eig(sigma)\n",
    "    v_inv = jnp.linalg.inv(v) \n",
    "    E = jnp.diag(jnp.clip(M,0,jnp.inf))+0.0001\n",
    "    return (v@E@v_inv).astype(float)\n",
    "    \n",
    "def _outer(a,b):\n",
    "    return jnp.outer(a,b)\n",
    "outer = jax.vmap(_outer, (0,0),0)\n",
    "outer_clients = jax.jit(jax.vmap(outer,(0,0),0))\n",
    "\n",
    "\n",
    "def _get_prob(a, mean, sigma): #should return the shape (L,n)\n",
    "    return guassian_pdf(a,mean,sigma)\n",
    "_get_prob_1 = jax.vmap(_get_prob, (0,None,None),0)\n",
    "get_prob = jax.vmap(_get_prob_1,(None,0,None),1)    \n",
    "\n",
    "@jax.jit\n",
    "def client_run(data, means,sigma, SS_1, SS_2, vss_1, vss_2):\n",
    "    def _get_ss2(prob_vec,data):\n",
    "        #probvec: (n), data: (n,d)\n",
    "        prob_vec = jnp.expand_dims(prob_vec, axis=1) # (n,1)\n",
    "        return jnp.mean(prob_vec*data ,axis=0) #(n,d) -> (d)\n",
    "    get_ss2 = jax.vmap(_get_ss2, (0,None),0) #(L,d)\n",
    "    \n",
    "    prob = get_prob(data,means,sigma) #(n,L)\n",
    "    sum_prob = jnp.sum(prob, axis=1)  #(n)\n",
    "    sum_prob = jnp.expand_dims(sum_prob,1) + 0.000001#(n,1)\n",
    "    raw_ss_1 = prob/sum_prob #(n,L)\n",
    "    ss_1 = jnp.mean(raw_ss_1, axis=0) #(L)\n",
    "    ss_2 = get_ss2(raw_ss_1.T, data) #(L,d)\n",
    "    delta1 = ss_1-SS_1-vss_1\n",
    "    delta2 = ss_2-SS_2-vss_2\n",
    "    return delta1, delta2\n",
    "\n",
    "parallel_client_run = jax.vmap(client_run, (0,None,None,None,None,0,0),0)\n",
    "\n",
    "def generate_data(key, hyper:NamedTuple):\n",
    "    #Do not jax.jit\n",
    "    key, *subkey = random.split(key, num=10+hyper.L)\n",
    "    subkey = (i for i in subkey)\n",
    "    means = random.normal(next(subkey), shape=(hyper.L,hyper.d))\n",
    "    sigma = jnp.cov(random.normal(next(subkey), shape=(hyper.d,hyper.d))@random.normal(next(subkey),shape=(hyper.d,100_000)))\n",
    "    source_data = [random.multivariate_normal(next(subkey), means[i], sigma,shape=(hyper.N,)) for i in range(hyper.L)]\n",
    "    logits  = random.dirichlet(next(subkey),1.5* jnp.array([1.0 for _ in range(hyper.L)]))\n",
    "    mixture_weights = jax.nn.softmax(logits)\n",
    "    cuts = random.categorical(next(subkey), logits, shape=(hyper.N,))\n",
    "    raw_data = jnp.vstack([dt[cuts==idx] for idx,dt in enumerate(source_data)])\n",
    "    clients_data = jnp.array(jnp.split(random.permutation(next(subkey),raw_data), hyper.n))\n",
    "    return key,means,sigma,mixture_weights,clients_data \n",
    "\n",
    "@jax.jit\n",
    "def compute_likelyhood(data, mixture, means,sigma ):\n",
    "    #Need to use the prob_function\n",
    "    likelyhood = get_prob(data, means, sigma)\n",
    "    likelyhood = jnp.expand_dims(mixture,axis=1) *likelyhood \n",
    "    return jnp.mean(likelyhood)\n",
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Main"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Hyper(NamedTuple):\n",
    "    #Hyperparameters with default settings..\n",
    "    p = 0.95 # partipation rate\n",
    "    L = 2 # length\n",
    "    b = 100 #batch size\n",
    "    N = 10_000 #total number of examples\n",
    "    n = 1000 # number of agents\n",
    "    d = 3 # dimension of the experiment\n",
    "    gamma = 10e-2 #hyper parameter\n",
    "    alpha = 10e-2 # the total things\n",
    "    epochs = 300\n",
    "    repeats = 1\n",
    "    seed = 42"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def main():\n",
    "    hyper = Hyper()\n",
    "    key = random.PRNGKey(hyper.seed)\n",
    "    # Generate the data\n",
    "    key, t_means,t_sigma,t_mixture_weights, clients_data =  generate_data(key, hyper)\n",
    "    yTy = outer_clients(clients_data,clients_data)\n",
    "    yTy = jnp.mean(yTy,axis=(0,1))\n",
    "    #Initialize the variables\n",
    "    key, means, sigma, mixture_weights, _ =  generate_data(key, hyper)\n",
    "    SS_1 , SS_2 = jnp.zeros(shape=(hyper.L,)), jnp.zeros(shape=(hyper.L, hyper.d))\n",
    "    V1 , V2 =  jnp.zeros(shape=(hyper.L,)), jnp.zeros(shape=(hyper.L, hyper.d))\n",
    "    H1 , H2 =  jnp.zeros(shape=(hyper.L,)), jnp.zeros(shape=(hyper.L, hyper.d))\n",
    "    #Variables list\n",
    "    Vss1 = jnp.zeros(shape=(hyper.n, hyper.L))\n",
    "    Vss2 = jnp.zeros(shape=(hyper.n,hyper.L, hyper.d))\n",
    "    optimal_value = compute_likelyhood(clients_data,t_mixture_weights,t_means,t_sigma)\n",
    "    optimal_gap = []\n",
    "    for i in tqdm(range(hyper.epochs)):\n",
    "        key, *subkey = random.split(key,num=hyper.n+2)\n",
    "        subkey = (_ for _ in subkey)  \n",
    "        indicator = random.bernoulli(next(subkey),hyper.p,shape=(hyper.n,))\n",
    "        participate = jnp.nonzero(indicator)[0]\n",
    "        batch_data = []\n",
    "        for client in list(participate):\n",
    "            batch_data.append(clients_data[client][random.permutation(next(subkey),20)[:hyper.b]])\n",
    "        batch_data = jnp.array(batch_data)                \n",
    "        delta1, delta2 = parallel_client_run(batch_data, means, sigma, SS_1, SS_2, Vss1[participate],Vss2[participate])\n",
    "        \n",
    "        #vectorize Vss updates. \n",
    "        Vss1 = Vss1.at[participate].set(hyper.alpha*delta1)\n",
    "        Vss2 = Vss2.at[participate].set(hyper.alpha*delta2)\n",
    "    \n",
    "        #Central Updates:\n",
    "        d1 = jnp.mean(delta1, axis=0)\n",
    "        d2 = jnp.mean(delta2,axis=0)\n",
    "        H1 = V1 + d1\n",
    "        H2 = V2 + d2\n",
    "        SS_1 = SS_1+hyper.gamma*H1\n",
    "        SS_2 = SS_2+hyper.gamma*H2\n",
    "        V1 = V1+hyper.alpha*d1\n",
    "        V2 = V2+hyper.alpha*d2\n",
    "\n",
    "        #calculate the new variables \n",
    "        mixture_weights = (1/jnp.sum(SS_1))*SS_1\n",
    "        means = jnp.expand_dims((1/SS_1),axis=1)*SS_2\n",
    "        sigma = yTy - jnp.sum(jnp.expand_dims(SS_1, axis=(1,2))*outer(means, means), axis=0)\n",
    "        sigma = get_psd(sigma)\n",
    "        sigma = 0.5*(sigma.T+sigma)\n",
    "        optimal_gap.append(float(jnp.abs(optimal_value -compute_likelyhood(clients_data,mixture_weights,means,sigma))))\n",
    "        print(optimal_gap)\n",
    "    print(\"optimality gap\")\n",
    "    print(optimal_gap)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Experiment Running"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "f5381989b6c5ff09e06861f3fcfeff032963fb6cbbe7a2ac426efbaceba8c983"
  },
  "kernelspec": {
   "display_name": "Python 3.8.12 ('fedjax-cpu')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
