{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "TqF0-AWHP5dW"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import numpy.linalg as linalg\n",
    "from sklearn.linear_model import Lasso\n",
    "from copy import deepcopy, copy \n",
    "from typing import NamedTuple\n",
    "from sklearn.exceptions import ConvergenceWarning\n",
    "from sklearn.utils._testing import ignore_warnings\n",
    "import matplotlib.pyplot as plt\n",
    "import wandb"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_psd(sigma):\n",
    "    M, v = np.linalg.eig(sigma)\n",
    "    v_inv = np.linalg.inv(v) \n",
    "    E = np.diag(np.clip(M,0,np.inf))+0.0001\n",
    "    return (v@E@v_inv).astype(float)    \n",
    "\n",
    "def get_obj_fct(lasso, hyper):\n",
    "    @ignore_warnings(category=ConvergenceWarning)\n",
    "    def obj_fct_n(Theta, client_codeword):\n",
    "        #This needs fiving\n",
    "        obj_fct = 0.0\n",
    "        for nn in range(hyper.n):\n",
    "            for t in range(client_codeword[nn].shape[0]):\n",
    "                y = client_codeword[nn][t]\n",
    "                lasso.fit(Theta.T, y) # involves solving a LASSO problem\n",
    "                hj = lasso.coef_\n",
    "                obj_fct += 0.5*linalg.norm(y - hj@Theta )**2 + hyper.lmbd*linalg.norm( hj, 1)\n",
    "        return (obj_fct + 0.5*hyper.eta* linalg.norm( Theta )**2)\n",
    "    return obj_fct_n\n",
    "\n",
    "\n",
    "# def quant(x, s):\n",
    "#     uni_noise = np.random.uniform(size=x.shape)\n",
    "#     #np.max , np.norm depends on the need for sparsity \n",
    "#     quant = np.floor(s/np.norm(x)*np.abs(x)+uni_noise)\n",
    "#     reconstruct  = quant-uni_noise\n",
    "#     return (1/s)*np.max(x)*np.sign(x)*reconstruct\n",
    "\n",
    "# def quant(x,s):\n",
    "#     uni_noise = np.random.uniform(size=x.shape)\n",
    "#     #np.max , np.norm depends on the need for sparsity \n",
    "#     quant = np.floor(s/linalg.norm(x)*np.abs(x)+uni_noise)\n",
    "#     reconstruct  = quant-uni_noise\n",
    "#     return (1/s)*linalg.norm(x)*np.sign(x)*reconstruct\n",
    "\n",
    "\n",
    "def quant(x, s):\n",
    "    return (1/s) * np.sign(x) * linalg.norm(x) * np.floor(s* np.abs(x)/(linalg.norm(x))+np.random.uniform(size=x.shape))\n",
    "\n",
    "\n",
    "def generate_data(hyper):\n",
    "    shared_dict = np.random.normal(size=(hyper.d,hyper.m))\n",
    "    client_codeword , client_data = [], [] \n",
    "    if hyper.homo_switch==0:\n",
    "        noise = 0.0001\n",
    "    else:\n",
    "        noise = 0\n",
    "    for nn in range(hyper.n): \n",
    "        client_data.append(np.random.normal(size=(hyper.T,hyper.d))* np.random.binomial(\n",
    "            1, 0.2,size=(hyper.T,hyper.d)))\n",
    "        client_codeword.append(client_data[nn]@shared_dict + noise*np.random.normal(size=(hyper.T,hyper.m)))\n",
    "    return shared_dict,client_codeword,client_data\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Experiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def main(hyper,wandb_log=False):\n",
    "    np.random.seed(hyper.seed)\n",
    "    _ , client_codeword, _ = generate_data(hyper)\n",
    "    init_dict , _ , _ = generate_data(hyper)\n",
    "    lasso = Lasso(alpha=hyper.lmbd, fit_intercept=False)\n",
    "    obj_fct_n = get_obj_fct(lasso, hyper)\n",
    "\n",
    "    p = (hyper.Participate/hyper.n)\n",
    "    obj_sto_all = []\n",
    "    theta_norm_all = []\n",
    "    @ignore_warnings(category=ConvergenceWarning)\n",
    "    def fit_client(x,y):\n",
    "        fitted = lasso.fit(x,y)\n",
    "        return fitted.coef_\n",
    "\n",
    "    for rep in range(hyper.rep_times):\n",
    "        theta = deepcopy(init_dict)\n",
    "        V_theta = [np.zeros(theta.shape) for _ in range(hyper.n)] \n",
    "        Msg_theta = [np.zeros(theta.shape) for _ in range(hyper.n)] \n",
    "        Va_theta, Ha_theta, D_theta = (np.zeros(theta.shape) for _ in range(3))\n",
    "        obj_sto = []\n",
    "        theta_norm = []\n",
    "        print(\"rep = \", rep, \" \\n\")\n",
    "        for t in range(hyper.IterNum):\n",
    "            if t%50 == 0:\n",
    "                obj_sto.append(obj_fct_n(theta, client_codeword))\n",
    "                theta_norm.append(linalg.norm(D_theta))\n",
    "                print( \"t \",t ,\" obj = \",  obj_sto[-1])\n",
    "                \n",
    "                if wandb_log==True:\n",
    "                    log_dict={\n",
    "                        \"Theta Update Norm\": theta_norm[-1],\n",
    "                        \"Objective Value\": obj_sto[-1] \n",
    "                    }\n",
    "                    wandb.log(log_dict)\n",
    "\n",
    "            idx_PP = np.random.permutation(hyper.n)[:hyper.Participate]\n",
    "            #for each client\n",
    "            for nn in idx_PP:\n",
    "                idx_batch = np.random.permutation(hyper.T)[:hyper.BatchSize]\n",
    "                yy = client_codeword[nn][idx_batch]\n",
    "                SS1 = np.zeros((hyper.d,hyper.d))\n",
    "                SS2 = np.zeros((hyper.m,hyper.d))\n",
    "                for b in range(hyper.BatchSize):\n",
    "                    hj = fit_client(theta.T, yy[b])\n",
    "                    SS1 += np.outer(hj,hj)\n",
    "                    SS2 += np.outer(yy[b],hj)\n",
    "                SS1 = SS1/hyper.BatchSize\n",
    "                SS2 = SS2/hyper.BatchSize\n",
    "                client_theta = SS2@( np.linalg.inv(SS1 + hyper.eta*np.eye(hyper.d)))  \n",
    "                client_theta = client_theta.T\n",
    "                Delta = client_theta - theta - V_theta[nn]\n",
    "                \n",
    "                ##Message conostruction\n",
    "                if hyper.squant!=0:\n",
    "                    V_theta[nn] = V_theta[nn]+(hyper.alpha/p)*quant(Delta, hyper.squant)\n",
    "                    Msg_theta[nn] = quant(Delta, hyper.squant)\n",
    "                else:\n",
    "                    Msg_theta[nn] = Delta\n",
    "                    V_theta[nn] = V_theta[nn]+(hyper.alpha/p)*Delta\n",
    "                \n",
    "\n",
    "            #Server Update\n",
    "            step_size = 0.1 / np.sqrt(t+0.1)\n",
    "            D_theta = (1/(hyper.n*p))*sum([Msg_theta[i] for i in idx_PP])\n",
    "            Ha_theta =  Va_theta + D_theta\n",
    "            Va_theta =Va_theta+(hyper.alpha/(hyper.n*p))*sum([Msg_theta[i] for i in idx_PP])\n",
    "            theta = theta+step_size* Ha_theta  \n",
    "\n",
    "        obj_sto_all.append(obj_sto)\n",
    "        theta_norm_all.append(theta_norm)\n",
    "    return obj_sto_all, theta_norm_all"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Run the experiment:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Hyper(NamedTuple):\n",
    "    seed = 42\n",
    "    ## Problems dimensions\n",
    "    d = 15 # original dimension\n",
    "    m = 10 # codeword dimension\n",
    "    n = 20 # number of workers\n",
    "    T = 50 # Samples per worker\n",
    "    homo_switch = 0 #0 for heter data, 1 for homo\n",
    "    surrogate = 1 #1 aggregating over the prameter space, 0 over the \n",
    "    #Loss function parameters\n",
    "    eta = 0.1 #dict l2 penalty weight\n",
    "    lmbd = 0.05 #codeword l1 penalty weight\n",
    "    rep_times = 1 # no. of repetition to run the experiment\n",
    "    # parameters for the algorithms \n",
    "    BatchSize = 20 # batch size per client per run\n",
    "    Participate = 5 # no of active workers each run\n",
    "    alpha = 0.01 # step size\n",
    "    squant = 0 # quantization level\n",
    "    IterNum = 10_000 # no. of iterations per experiment\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "izGGCgSYYgdL"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rep =  0  \n",
      "\n",
      "t  0  obj =  549.9240389094546\n",
      "t  50  obj =  642.1328465620952\n",
      "t  100  obj =  717.2954556980202\n",
      "t  150  obj =  774.5473009570931\n",
      "t  200  obj =  812.3616495180538\n",
      "t  250  obj =  841.1223709985038\n",
      "t  300  obj =  866.0859934566923\n",
      "t  350  obj =  888.3366994752896\n",
      "t  400  obj =  902.424246714035\n",
      "t  450  obj =  908.8740350624294\n",
      "t  500  obj =  911.7025454910272\n",
      "t  550  obj =  916.0173224454983\n",
      "t  600  obj =  921.5427562063003\n",
      "t  650  obj =  925.5650244851655\n",
      "t  700  obj =  931.8777895788724\n",
      "t  750  obj =  938.4938153635626\n",
      "t  800  obj =  942.4765577604682\n",
      "t  850  obj =  945.8479023391911\n",
      "t  900  obj =  947.7786013832239\n",
      "t  950  obj =  950.867654139467\n",
      "t  1000  obj =  953.290601903602\n",
      "t  1050  obj =  955.9411041272496\n",
      "t  1100  obj =  958.1655110911607\n",
      "t  1150  obj =  958.7510838742255\n",
      "t  1200  obj =  958.4302018396165\n",
      "t  1250  obj =  956.8889652604394\n",
      "t  1300  obj =  955.2755106478737\n",
      "t  1350  obj =  954.3874876141064\n",
      "t  1400  obj =  953.0983331799604\n",
      "t  1450  obj =  951.8368390572293\n",
      "t  1500  obj =  950.8354203887782\n",
      "t  1550  obj =  949.7327485959541\n",
      "t  1600  obj =  949.5736212879997\n",
      "t  1650  obj =  948.7482582733088\n",
      "t  1700  obj =  948.4683846648102\n",
      "t  1750  obj =  948.0687061186152\n",
      "t  1800  obj =  947.6997111466151\n",
      "t  1850  obj =  947.2374119371874\n",
      "t  1900  obj =  946.0954835831211\n",
      "t  1950  obj =  945.9558886391997\n",
      "t  2000  obj =  945.3528321098898\n",
      "t  2050  obj =  945.1377413456904\n"
     ]
    }
   ],
   "source": [
    "hyper = Hyper()\n",
    "# wandb.login()\n",
    "# wandb.init(project='FedSur', name='Fed Dict Par Learn', config=Hyper()._asdict())\n",
    "main(Hyper(), wandb_log=False)"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "FedDictLearn-SynData.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
