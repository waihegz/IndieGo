{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Goals**\n",
    "\n",
    "1. Get this thing organized and working in numpy \n",
    "1. If really really needed do it in JAX"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "TqF0-AWHP5dW"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import numpy.linalg as linalg\n",
    "from sklearn.linear_model import Lasso\n",
    "from copy import deepcopy, copy \n",
    "from typing import NamedTuple\n",
    "from sklearn.exceptions import ConvergenceWarning\n",
    "from sklearn.utils._testing import ignore_warnings"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_psd(sigma):\n",
    "    M, v = np.linalg.eig(sigma)\n",
    "    v_inv = np.linalg.inv(v) \n",
    "    E = np.diag(np.clip(M,0,np.inf))+0.0001\n",
    "    return (v@E@v_inv).astype(float)    \n",
    "\n",
    "def get_obj_fct(lasso, hyper):\n",
    "    #Something is wrong here...#TODO very wrong\n",
    "    @ignore_warnings(category=ConvergenceWarning)\n",
    "    def obj_fct_n(Theta, client_codeword):\n",
    "        #This needs fiving\n",
    "        obj_fct = 0.0\n",
    "        for nn in range(hyper.n):\n",
    "            for t in range(client_codeword[nn].shape[0]):\n",
    "                y = client_codeword[nn][t]\n",
    "                lasso.fit(Theta.T, y) # involves solving a LASSO problem\n",
    "                hj = lasso.coef_\n",
    "                obj_fct += 0.5*linalg.norm(y - hj@Theta )**2 + hyper.lmbd*linalg.norm( hj, 1)\n",
    "        return (obj_fct + 0.5*hyper.eta* linalg.norm( Theta )**2)\n",
    "    return obj_fct_n\n",
    "\n",
    "def quant(x, s):\n",
    "    #TODO\n",
    "    return x\n",
    "    # return (1/s) * np.sign(x) * linalg.norm(x) * np.floor(s* np.abs(x)/(linalg.norm(x))* \n",
    "    #                                                       np.random.uniform(size=x.shape))\n",
    "   \n",
    "    \n",
    "class Hyper(NamedTuple):\n",
    "    ## Problems dimensions\n",
    "    d = 15 # original dimension\n",
    "    m = 10 # codeword dimension\n",
    "    n = 20 # number of workers\n",
    "    T = 50 # Samples per worker\n",
    "    homo_switch = 0 #0 for homogenous data, 1 for hetero\n",
    "    #Loss function parameters\n",
    "    eta = 0.1 #dict l2 penalty weight\n",
    "    lmbd = 0.05 #codeword l1 penalty weight\n",
    "    rep_times = 10 # no. of repetition to run the experiment\n",
    "    # parameters for the algorithms \n",
    "    BatchSize = 3 # batch size per client per run\n",
    "    Participate = 5 # no of active workers each run\n",
    "    alpha = 0.01 # step size\n",
    "    squant = 15 # quantization level\n",
    "    IterNum = 5000 # no. of iterations per experiment\n",
    "    \n",
    "def generate_data(hyper:Hyper):\n",
    "    shared_dict = np.random.normal(size=(hyper.d,hyper.m))\n",
    "    client_codeword , client_data = [], [] \n",
    "    for nn in range(hyper.n): \n",
    "        client_data.append(np.random.uniform(size=(hyper.T,hyper.d))* np.random.binomial(\n",
    "            1, 0.2,size=(hyper.T,hyper.d)))\n",
    "        client_codeword.append(client_data[nn]@shared_dict + 0.0001*np.random.normal(size=(hyper.T,hyper.m)))\n",
    "    if hyper.homo_switch == 0:\n",
    "        return shared_dict,client_codeword,client_data\n",
    "    else:\n",
    "        raise NotImplementedError\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Experiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hyper = Hyper()\n",
    "true_dict, client_codeword, client_data = generate_data(hyper)\n",
    "lasso = Lasso(alpha=hyper.lmbd, fit_intercept=False, max_iter=5000)\n",
    "init_dict,_,_ = generate_data(hyper)\n",
    "## Take care of homogenous experiment\n",
    "if hyper.homo_switch == 1:\n",
    "    client_codeword = np.stack(client_codeword)\n",
    "    client_codeword = [client_codeword for i in range(hyper.n)]    \n",
    "## functionals\n",
    "lasso = Lasso(alpha=hyper.lmbd, fit_intercept=False, max_iter=5000)\n",
    "obj_fct_n = get_obj_fct(lasso, hyper)\n",
    "## experiment setup\n",
    "\n",
    "p = (hyper.Participate/hyper.n)\n",
    "obj_sto_all = []"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "BTHzxQMTF5NH"
   },
   "source": [
    "## The Code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "izGGCgSYYgdL"
   },
   "outputs": [],
   "source": [
    "@ignore_warnings(category=ConvergenceWarning)\n",
    "def fit_client(x,y):\n",
    "    fitted = lasso.fit(x,y)\n",
    "    return fitted.coef_\n",
    "\n",
    "for rep in range(hyper.rep_times):\n",
    "    Theta = copy(init_dict)\n",
    "    V_SS1 = [np.zeros((hyper.d,hyper.d)) for _ in range(hyper.n)] \n",
    "    V_SS2 = [np.zeros((hyper.m,hyper.d)) for _ in range(hyper.n)] \n",
    "    Msg_SS1 = [np.zeros((hyper.d,hyper.d)) for _ in range(hyper.n)] \n",
    "    Msg_SS2 = [np.zeros((hyper.m,hyper.d)) for _ in range(hyper.n)] \n",
    "    Va_SS1, Ha_SS1, Sa_SS1 = np.zeros((hyper.d,hyper.d)), np.zeros((hyper.d,hyper.d)),np.zeros((hyper.d,hyper.d)) \n",
    "    Va_SS2, Ha_SS2, Sa_SS2 = np.zeros((hyper.m,hyper.d)),np.zeros((hyper.m,hyper.d)),np.zeros((hyper.m,hyper.d))\n",
    "    #Traclking objective functions.\n",
    "    obj_sto = []\n",
    "    print(\"rep = \", rep, \" \\n\")\n",
    "    for t in range(hyper.IterNum):\n",
    "        if t%10 == 0:\n",
    "            print( t , \", obj = \")\n",
    "            obj_sto.append(obj_fct_n(Theta, client_codeword))\n",
    "            print( obj_sto[-1], \" \" );\n",
    "        \n",
    "        idx_PP = np.random.permutation(hyper.n)[:hyper.Participate]\n",
    "        \n",
    "        #for each client\n",
    "        for nn in idx_PP:\n",
    "            #batch data\n",
    "            if hyper.homo_switch == 0:\n",
    "                idx_batch = np.random.permutation(hyper.T)[:hyper.BatchSize]\n",
    "                yy = client_codeword[nn][idx_batch]\n",
    "            else:\n",
    "                idx_batch = np.random.permutation(hyper.n*hyper.T)[:hyper.BatchSize]\n",
    "                yy = client_codeword[nn][idx_batch] \n",
    "\n",
    "            #client message\n",
    "            SS1 = np.zeros((hyper.d,hyper.d))\n",
    "            SS2 = np.zeros((hyper.m,hyper.d))\n",
    "            for b in range(hyper.BatchSize):\n",
    "                hj = fit_client(Theta.T, yy[b])\n",
    "                SS1 += np.outer(hj,hj)\n",
    "                SS2 += np.outer(yy[b],hj)\n",
    "\n",
    "            ##Message conostruction\n",
    "            Delta1 = SS1/hyper.BatchSize - Sa_SS1 - V_SS1[nn]\n",
    "            Delta2 = SS2/hyper.BatchSize - Sa_SS2 - V_SS2[nn]\n",
    "            # V_SS1[nn] = V_SS1[nn] + (hyper.alpha/p)*quant(Delta1, hyper.squant)\n",
    "            # V_SS2[nn] = V_SS2[nn] + (hyper.alpha/p)*quant(Delta2, hyper.squant)\n",
    "            Msg_SS1[nn] = quant(Delta1, hyper.squant)\n",
    "            Msg_SS2[nn] = quant(Delta2, hyper.squant); \n",
    "        \n",
    "\n",
    "        #Server Update\n",
    "        step_size = 0.1 / np.sqrt(t+0.1)\n",
    "        D_SS1 = (1/(hyper.n*p))*sum([Msg_SS1[i] for i in idx_PP])\n",
    "        D_SS2 = (1/(hyper.n*p))*sum([Msg_SS2[i] for i in idx_PP])    \n",
    "\n",
    "        Ha_SS1 = Va_SS1 + D_SS1\n",
    "        Ha_SS2 = Va_SS2 + D_SS2\n",
    "        \n",
    "\n",
    "        Sa_SS1 = Sa_SS1 + step_size*Ha_SS1\n",
    "        Sa_SS1 = get_psd(0.5*(Sa_SS1+Sa_SS1.T))\n",
    "        Sa_SS2 = Sa_SS2 + step_size*Ha_SS2\n",
    "        \n",
    "        # Va_SS1 = Va_SS1 + (hyper.alpha/(hyper.n*p))*sum([Msg_SS1[i] for i in idx_PP])\n",
    "        # Va_SS2 = Va_SS2 + (hyper.alpha/(hyper.n*p))*sum([Msg_SS2[i] for i in idx_PP])\n",
    "        Theta = Sa_SS2 @ ( np.linalg.inv(Sa_SS1 + hyper.eta*np.eye(hyper.d)))\n",
    "        Theta = Theta.T  \n",
    "        # Theta =  (Sa_SS2@((Sa_SS1 + hyper.eta*np.eye(hyper.d))**(-1))).T \n",
    "\n",
    "    obj_sto_all.append(obj_sto)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "FedDictLearn-SynData.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
