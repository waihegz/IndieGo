{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "C56-zdm5xNW4"
      },
      "source": [
        "##Installs and Imports"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Za-SSUVd0GBh",
        "outputId": "44844995-0d38-4023-c4d0-e2f0122fa0de"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "NVIDIA-SMI has failed because you are not:\n",
            "\ta) running as an administrator or\n",
            "\tb) there is not at least one TCC device in the system\n",
            "\n"
          ]
        }
      ],
      "source": [
        "!nvidia-smi"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Q7ByvjrSUPHm"
      },
      "outputs": [],
      "source": [
        "import jax\n",
        "import jax.numpy as jnp\n",
        "import haiku as hk \n",
        "import numpy as np\n",
        "import fedjax\n",
        "from tqdm import tqdm\n",
        "import random\n",
        "from jax.tree_util import tree_multimap\n",
        "from typing import NamedTuple , Callable, Any, Tuple, Sequence, Mapping, Any, Optional\n",
        "from copy import deepcopy\n",
        "import wandb"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "S-rkN5e-p2qt"
      },
      "source": [
        "##Installs and Imports"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1YBTDo76p2qt"
      },
      "outputs": [],
      "source": [
        "# Uncomment these to install fedjax.\n",
        "!pip install --quiet wandb\n",
        "!pip install --quiet dm-haiku\n",
        "!pip install --quiet fedjax"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3sWQEhFKp2qu"
      },
      "outputs": [],
      "source": [
        "import jax\n",
        "import jax.numpy as jnp\n",
        "import haiku as hk \n",
        "import numpy as np\n",
        "import torch \n",
        "import torchvision\n",
        "import fedjax\n",
        "from tqdm import tqdm\n",
        "import random\n",
        "from jax.tree_util import tree_multimap\n",
        "from typing import NamedTuple , Callable, Any, Tuple, Sequence, Mapping, Any, Optional\n",
        "from copy import deepcopy"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4-SJ1h7ep2qu"
      },
      "source": [
        "##Datasets"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EtUVRo6gp2qu"
      },
      "outputs": [],
      "source": [
        "def load_dataset(hyper: NamedTuple ):\n",
        "    \"\"\" \n",
        "        Utilities to return federated datases synthesized from common datasets\n",
        "        using a Dirichlet distirbutino acocrding to. \n",
        "\n",
        "    \"\"\"\n",
        "    pass\n",
        "\n",
        "\n",
        "def load_emnist(hyper: NamedTuple):\n",
        "    \"\"\"\n",
        "        Changing the built-in federated-emnist dataset to an inMemoryDataset, \n",
        "        and using the hyperparameter named to tuple to corrupt some of the\n",
        "        data if needed. \n",
        "    \"\"\"\n",
        "    train, test = fedjax.datasets.emnist.load_data(only_digits=False)\n",
        "    id_list = list(train.client_ids())\n",
        "    train_inMemory = {}\n",
        "    test_inMemory = {}\n",
        "    for idx, i in enumerate(id_list):\n",
        "        client_train = train.get_client(i).all_examples()\n",
        "        client_test  = test.get_client(i).all_examples()\n",
        "        train_inMemory[idx] = {'x':client_train['x'] , 'y':client_train['y']} \n",
        "        test_inMemory[idx]  =  {'x':client_test['x'] , 'y':client_test['y']}\n",
        "    id_list = list(train_inMemory.keys())\n",
        "    if hyper.adversary == True: \n",
        "        random.shuffle(id_list)\n",
        "        adversary_list = id_list[:round(hyper.corrupt_ratio*len(id_list))]\n",
        "    else:\n",
        "        adversary_list = []\n",
        "    for i in adversary_list:\n",
        "        train_inMemory[i]['y'] = np.random.randint(0,62,size=train_inMemory[i]['y'].shape)\n",
        "    train = fedjax.InMemoryFederatedData(train_inMemory)\n",
        "    test  = fedjax.InMemoryFederatedData(test_inMemory)\n",
        "    return train, test, adversary_list"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SJHlpysap2qu"
      },
      "source": [
        "##Aggregators"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OG87OjCup2qv"
      },
      "outputs": [],
      "source": [
        "def krum(tree_list: Sequence[fedjax.Params], m:int=4, f:int=2):\n",
        "    @jax.jit\n",
        "    def tree_l2_dist(x, y):\n",
        "        return fedjax.tree_util.tree_l2_norm(tree_multimap(lambda a,b: a-b, x, y))\n",
        "\n",
        "    n = len(tree_list)\n",
        "    dist_array = jnp.zeros((n,n))\n",
        "    for i in range(n):\n",
        "        for j in range(i+1,n):\n",
        "            dist_array = dist_array.at[i,j].set(tree_l2_dist(tree_list[i],tree_list[j]))\n",
        "    dist_array = dist_array + dist_array.T\n",
        "    for i in range(n):\n",
        "        dist_array = dist_array.at[i,i].set(jnp.inf)\n",
        "    dist_array = jnp.sort(dist_array,axis=1)\n",
        "    dist_array = dist_array[:,:n-f]\n",
        "    dist_array = jnp.sum(dist_array, axis=1)\n",
        "    sorted_indices = jnp.argsort(dist_array)[:m]\n",
        "    multi_krum_list = [(tree_list[i],1) for i in sorted_indices]\n",
        "    return fedjax.tree_util.tree_mean(multi_krum_list)\n",
        "\n",
        "def projectedKrum():\n",
        "    \"\"\"A projection based acceleration of krum\"\"\"\n",
        "    return \n",
        "\n",
        "def coordinate_median():\n",
        "    pass"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5eYJb05_p2qv"
      },
      "source": [
        "##Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "L_ob1B3fp2qv"
      },
      "outputs": [],
      "source": [
        "_SAMPLE_MNIST_BATCH = {\n",
        "    'x': np.zeros((1, 28, 28, 1), dtype=np.float32),\n",
        "    'y': np.zeros(1, dtype=np.float32)\n",
        "    }\n",
        "\n",
        "\n",
        "_TRAIN_LOSS = lambda b, p: fedjax.metrics.unreduced_cross_entropy_loss(b['y'], p)\n",
        "\n",
        "_EVAL_METRICS = {\n",
        "    'loss': fedjax.metrics.CrossEntropyLoss(),\n",
        "    'accuracy': fedjax.metrics.Accuracy()\n",
        "}\n",
        "\n",
        "class mnist_conv(hk.Module):\n",
        "    def __init__(self, num_classes:int, dropout_rate=0.25):\n",
        "        super().__init__()\n",
        "        self._num_classes = num_classes\n",
        "        self._rate = dropout_rate\n",
        "    \n",
        "    def __call__(self, x:jnp.ndarray, is_train: bool):\n",
        "        x = hk.Conv2D(output_channels=16, kernel_shape=(5, 5), padding='VALID')(x)\n",
        "        x = (\n",
        "            hk.MaxPool(\n",
        "                window_shape=(1, 2, 2, 1), strides=(1, 2, 2, 1),\n",
        "                padding='VALID')(x))\n",
        "        x = jax.nn.relu(x)\n",
        "        x = (\n",
        "            hk.MaxPool(\n",
        "                window_shape=(1, 2, 2, 1), strides=(1, 2, 2, 1),\n",
        "                padding='VALID')(x))\n",
        "        x = hk.Conv2D(output_channels=32, kernel_shape=(5, 5), padding='VALID')(x)\n",
        "        x = jax.nn.relu(x)\n",
        "        x = (\n",
        "            hk.MaxPool(\n",
        "                window_shape=(1, 2, 2, 1), strides=(1, 2, 2, 1),\n",
        "                padding='VALID')(x))\n",
        "        \n",
        "        # # if is_train:\n",
        "        #     x = hk.dropout(rng=hk.next_rng_key(), rate=self._rate, x=x)\n",
        "        x = hk.Flatten()(x)\n",
        "        x = hk.Linear(512)(x)\n",
        "        x = jax.nn.relu(x)\n",
        "        x = hk.Linear(512)(x)\n",
        "        x = jax.nn.relu(x)\n",
        "        # if is_train:\n",
        "        #     x = hk.dropout(rng=hk.next_rng_key(), rate=self._rate, x=x)\n",
        "        x = hk.Linear(self._num_classes)(x)\n",
        "        return x\n",
        "\n",
        "def create_mnist_cnn(num_classes, dropout_rate=0.25):\n",
        "        \n",
        "        def forward_pass(batch, is_train=True):\n",
        "            return mnist_conv(num_classes, dropout_rate)(batch['x'], is_train)\n",
        "\n",
        "        transformed_forward_pass = hk.transform(forward_pass)\n",
        "        return fedjax.create_model_from_haiku(\n",
        "            transformed_forward_pass=transformed_forward_pass,\n",
        "            sample_batch=_SAMPLE_MNIST_BATCH,\n",
        "            train_loss=_TRAIN_LOSS, \n",
        "            eval_metrics = _EVAL_METRICS,\n",
        "            train_kwargs={'is_train': True},\n",
        "            eval_kwargs={'is_train': False})"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4hyOQF6Vp2qv"
      },
      "source": [
        "##Implementation of Ditto"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-xkWR5Y6p2qv"
      },
      "outputs": [],
      "source": [
        "def DittoClient(client_model, client_optimizer, lmbd=20):\n",
        "    \"\"\" \n",
        "        client_model : functional form of client model to be used in training\n",
        "        client_optimizer: function form of client_optimizer to be used in trainig\n",
        "        RETURN a named tuple with client_init, client_step, client_final\n",
        "        this is supposed to execute the client_steps, and client_final will \n",
        "        return the update signal to the server.  \n",
        "        As a design principle the loss will be calculate withint here,\n",
        "    \"\"\"\n",
        "    class ToReturn(NamedTuple):\n",
        "        init: Callable\n",
        "        step: Callable\n",
        "        final: Callable\n",
        "    \n",
        "    def server_loss_fn(params,batch, rng):\n",
        "       preds =  client_model.apply_for_train(params, batch, rng)\n",
        "       example_loss = client_model.train_loss(batch, preds)\n",
        "       return jnp.mean(example_loss)\n",
        "    \n",
        "    def client_loss_fn(client_params, server_params,batch, rng):\n",
        "       preds =  client_model.apply_for_train(client_params, batch, rng)\n",
        "       example_loss = client_model.train_loss(batch, preds)\n",
        "       distance = jax.tree_util.tree_multimap(lambda a, b: a - b,\n",
        "                                                    client_params,\n",
        "                                                    server_params)\n",
        "       distance_l2 = fedjax.tree_util.tree_l2_norm(distance)\n",
        "       loss = jnp.mean(example_loss)+ (lmbd/2)*(distance_l2**2)\n",
        "       return loss\n",
        "    \n",
        "    server_grad_fn = jax.jit(jax.grad(server_loss_fn))\n",
        "    client_grad_fn = jax.jit(jax.grad(client_loss_fn))\n",
        "    \n",
        "    def client_init(server_params, client_input):\n",
        "        client_rng = client_input['key']\n",
        "        server_opt_state = client_optimizer.init(server_params.server_params)\n",
        "        client_opt_state = client_optimizer.init(client_input['client_params'])\n",
        "        client_step_state = {\n",
        "            'server_params': server_params.server_params,\n",
        "            'client_params': client_input['client_params'],\n",
        "            'server_opt_state': server_opt_state,\n",
        "            'client_opt_state': client_opt_state, \n",
        "            'rng': client_rng,\n",
        "            'iter_numb':0\n",
        "        }\n",
        "        return client_step_state\n",
        "\n",
        "    def client_step(client_step_state, batch):\n",
        "        rng, use_rng = jax.random.split(client_step_state['rng'])\n",
        "        server_grads = server_grad_fn(client_step_state['server_params'], batch, use_rng)\n",
        "        client_grads = client_grad_fn(client_step_state['client_params'],\n",
        "                                      client_step_state['server_params'],\n",
        "                                      batch, use_rng)\n",
        "        \n",
        "        server_opt_state, server_params = client_optimizer.apply(server_grads,\n",
        "                                                    client_step_state['server_opt_state'],\n",
        "                                                    client_step_state['server_params'])\n",
        "        client_opt_state, client_params = client_optimizer.apply(client_grads,\n",
        "                                                    client_step_state['client_opt_state'],\n",
        "                                                    client_step_state['client_params'])\n",
        "        next_client_step_state = {\n",
        "            'server_params': server_params,\n",
        "            'client_params': client_params,\n",
        "            'server_opt_state': server_opt_state,\n",
        "            'client_opt_state': client_opt_state, \n",
        "            'rng': rng,\n",
        "            'iter_numb':client_step_state['iter_numb']+1\n",
        "        }\n",
        "        return next_client_step_state\n",
        "    \n",
        "    def client_final(server_params, client_step_state):\n",
        "        delta_params = jax.tree_util.tree_multimap(lambda a, b: a - b,\n",
        "                                                    server_params.server_params,\n",
        "                                                    client_step_state['server_params'])\n",
        "        \n",
        "        return delta_params, client_step_state['iter_numb'], client_step_state['client_params']\n",
        "    \n",
        "    return ToReturn(client_init, client_step, client_final)\n",
        "\n",
        "\n",
        "@fedjax.dataclass\n",
        "class ServerState:\n",
        "    server_params : fedjax.Params\n",
        "    client_params: Mapping[Any, fedjax.Params]\n",
        "    opt_state: fedjax.OptState\n",
        "    adversary_list : list\n",
        "\n",
        "def Ditto(ForClient, \n",
        "           server_optimizer, \n",
        "           client_batch_hparams, \n",
        "           aggregator=None):\n",
        "    def init(params: fedjax.Params, adversary_list, client_ids):        \n",
        "        opt_state = server_optimizer.init(params)\n",
        "        client_params = {ids: deepcopy(params) for ids in client_ids}\n",
        "        return ServerState(params, client_params, opt_state, adversary_list) \n",
        "    \n",
        "    def apply(server_state: ServerState,\n",
        "        clients: Sequence[Tuple[Any, fedjax.ClientDataset, fedjax.PRNGKey]], \n",
        "        server_rng: Optional[Any] =None\n",
        "        ) -> Tuple[ServerState, Mapping[Any, Any]]:\n",
        "\n",
        "        client_models = server_state.client_params\n",
        "        client_diagnostics = {}\n",
        "        client_delta_params_weights = []       \n",
        "        for_each_client_update = fedjax.for_each_client(ForClient.init,\n",
        "                                                        ForClient.step,\n",
        "                                                        ForClient.final)\n",
        "\n",
        "        ##need to inject code here\n",
        "        batched_clients_data = [\n",
        "            (cid, cds.shuffle_repeat_batch(client_batch_hparams), \n",
        "             {'key':crng,'client_params':server_state.client_params[cid]}) for cid, cds, crng in clients]\n",
        "\n",
        "        data_length = {cid:len(cds) for cid, cds, _ in clients}\n",
        "\n",
        "        for client_id, (delta_params,iter_numb, new_client_params) in for_each_client_update(server_state,\n",
        "                                                            batched_clients_data):\n",
        "            \n",
        "            client_delta_params_weights.append((delta_params, len(data_length)))\n",
        "            client_models[client_id] = new_client_params\n",
        "            client_diagnostics[client_id] = {\n",
        "                'delta_l2_norm': fedjax.tree_util.tree_l2_norm(delta_params),\n",
        "                'iter_numb':iter_numb}\n",
        "\n",
        "        ##Updating the server\n",
        "        if aggregator==None:\n",
        "            mean_delta_params = fedjax.tree_util.tree_mean(client_delta_params_weights)\n",
        "        else:\n",
        "            mean_delta_params = aggregator([tree_param for tree_param,_ in client_delta_params_weights])\n",
        "        server_state = server_update(server_state, mean_delta_params,client_models)\n",
        "        return server_state, client_diagnostics\n",
        "\n",
        "    def server_update(server_state, mean_delta_params,client_models):\n",
        "        opt_state, params = server_optimizer.apply(mean_delta_params,\n",
        "                                                server_state.opt_state,\n",
        "                                                server_state.server_params)\n",
        "        return ServerState(params, client_models,opt_state,server_state.adversary_list)\n",
        "\n",
        "    return fedjax.FederatedAlgorithm(init, apply)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jwWAX5Nhp2qw"
      },
      "source": [
        "##Main Function"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EGVjB8GDo0Y7"
      },
      "outputs": [],
      "source": [
        "def main(hyper, wandb_log=False):\n",
        "    random.seed(hyper.seed)\n",
        "    np.random.seed(hyper.seed)\n",
        "    rng = jax.random.PRNGKey(hyper.seed)\n",
        "\n",
        "    num_classes = 62\n",
        "    model = create_mnist_cnn(num_classes=num_classes, dropout_rate=hyper.dropout_rate)\n",
        "    init_params = model.init(rng)\n",
        "\n",
        "    train, test, adversary_list = load_emnist(hyper)\n",
        "    client_optimizer = fedjax.optimizers.sgd(hyper.client_lr)\n",
        "    server_optimizer = fedjax.optimizers.sgd(hyper.server_lr)\n",
        "    if hyper.step_per_client == None:\n",
        "        client_batch_hparams = fedjax.ShuffleRepeatBatchHParams(\n",
        "                                        batch_size=hyper.samples_per_client)\n",
        "    else:\n",
        "        client_batch_hparams = fedjax.ShuffleRepeatBatchHParams(\n",
        "                                        batch_size=hyper.samples_per_client,\n",
        "                                        num_steps =hyper.step_per_client)\n",
        "\n",
        "    ForClient = DittoClient(model, client_optimizer)\n",
        "    client_ids = list(train.client_ids())\n",
        "    if hyper.use_aggregator == True:\n",
        "        FedAlgorithm = Ditto(ForClient,server_optimizer, client_batch_hparams,krum)\n",
        "    else:\n",
        "        FedAlgorithm = Ditto(ForClient,server_optimizer, client_batch_hparams)\n",
        "\n",
        "    rng, subkey = jax.random.split(rng)\n",
        "    server_state = FedAlgorithm.init(init_params,adversary_list,client_ids)\n",
        "\n",
        "    train_client_sampler = fedjax.client_samplers.UniformGetClientSampler(\n",
        "            fd=train, num_clients = hyper.clients_per_round, seed=hyper.seed)\n",
        "\n",
        "    batched_train_data = {cid:cds.shuffle_repeat_batch(batch_size = 20) for cid, cds in train.get_clients(client_ids)}   \n",
        "    batched_test_data = {cid:cds.shuffle_repeat_batch(batch_size = 20) for cid, cds in test.get_clients(client_ids)}\n",
        "            \n",
        "    train_eval_datasets = [cds for _, cds in train.get_clients(client_ids)]   \n",
        "    test_eval_datasets = [cds for _, cds in test.get_clients(client_ids)]\n",
        "    \n",
        "\n",
        "\n",
        "    \n",
        "    for round_num in tqdm(range(1, hyper.round_num)):\n",
        "        clients = train_client_sampler.sample()\n",
        "        server_state, client_diagnostics = FedAlgorithm.apply(server_state, clients)\n",
        "        if round_num%10 == 0:\n",
        "            #Only test the accuracy of the non-byzantine workers. \n",
        "            client_ids = [cid for cid, _, _ in clients if cid not in \n",
        "                            server_state.adversary_list]\n",
        "            \n",
        "            train_eval_batches = fedjax.padded_batch_client_datasets(\n",
        "                train_eval_datasets, batch_size=256)\n",
        "            test_eval_batches = fedjax.padded_batch_client_datasets(\n",
        "                test_eval_datasets, batch_size=256)\n",
        "\n",
        "            train_metrics = fedjax.evaluate_model(model, server_state.server_params,\n",
        "                                                    train_eval_batches)\n",
        "            test_metrics = fedjax.evaluate_model(model, server_state.server_params,\n",
        "                                                test_eval_batches)\n",
        "            \n",
        "            ditto_train_accuracy = []\n",
        "            ditto_test_accuracy = []\n",
        "            train_acc_tally, test_acc_tally = [], []\n",
        "            for indx, id in enumerate(client_ids):\n",
        "                client_train_metrics = fedjax.evaluate_model(model, server_state.client_params[id],\n",
        "                                                        batched_train_data[id])\n",
        "                client_test_metrics =  fedjax.evaluate_model(model, server_state.client_params[id],\n",
        "                                                    batched_test_data[id])\n",
        "                train_acc_tally.append(client_train_metrics['accuracy'])\n",
        "                test_acc_tally.append(client_test_metrics['accuracy'])\n",
        "            \n",
        "            log_dict = {\n",
        "                'ditto_train_accuracy': float(sum(train_acc_tally)/len(train_acc_tally)),\n",
        "                'ditto_test_accuracy': float(sum(test_acc_tally)/len(test_acc_tally)),\n",
        "                'train_accuracy': float(train_metrics['accuracy']), \n",
        "                'train_loss' : float(train_metrics['loss']), \n",
        "                'test_accuracy': float(test_metrics['accuracy']), \n",
        "                'test_loss' : float(test_metrics['loss'])\n",
        "            }\n",
        "            if wandb_log == True:\n",
        "                wandb.log(log_dict)\n",
        "            print(f'[round {round_num}] metrics={log_dict}')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rYz6ZUlc-i-o"
      },
      "source": [
        "##Running code:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sr-4wPDJp2qw"
      },
      "outputs": [],
      "source": [
        "class hyperparameters(NamedTuple):\n",
        "    round_num : int = 1000\n",
        "    clients_per_round : int = 10\n",
        "    samples_per_client : int = 20\n",
        "    client_lr :float = 0.01\n",
        "    server_lr :float = 1\n",
        "    seed :int = 42 \n",
        "    dropout_rate: float = 0.25\n",
        "    adversary: bool = False  \n",
        "    corrupt_ratio: float = 0.20\n",
        "    aggregator: str = 'krum'\n",
        "    use_aggregator: bool = False\n",
        "    step_per_client = None"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lMPe7vX21DHY"
      },
      "outputs": [],
      "source": [
        "wandb.login()\n",
        "wandb.init(project='Graduate Project', name='Ditto Run', config=hyperparameters()._asdict())\n",
        "main(hyperparameters(), wandb_log=True)"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [],
      "machine_shape": "hm",
      "name": "Experimental_Ditto.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.12"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
